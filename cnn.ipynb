{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fashion_dataset = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE NORMALIZING:\n",
      "IMAGES:  255\n",
      "LABELS:  9\n"
     ]
    }
   ],
   "source": [
    "print(\"BEFORE NORMALIZING:\")\n",
    "print(\"IMAGES: \",train_images.max()) # RANGE: 0-255\n",
    "print(\"LABELS: \",train_labels.max()) # RANGE: 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER NORMALIZING:\n",
      "IMAGES:  1.0\n",
      "IMAGES:  1.0\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "print(\"AFTER NORMALIZING:\")\n",
    "print(\"IMAGES: \",train_images.max()) # RANGE: 0-1\n",
    "print(\"IMAGES: \",test_images.max()) # RANGE: 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(2,2))\n",
    "# plt.imshow(train_images[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# CONVERT (x,y) -> (x,y,c)\n",
    "train_images = train_images.reshape(*train_images.shape, 1).astype(np.float32)\n",
    "test_images = test_images.reshape(*test_images.shape, 1).astype(np.float32)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvUnit(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size):              # \"kernel_size\" - 3 or (3,3) | \"input_shape\" passed to first block\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size)\n",
    "        self.bn   = layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, input_tensor, training=False):               # \"training\" - depends on FIT or EVALUATE (BN or DROPOUT)\n",
    "        t = self.conv(input_tensor)\n",
    "        t = self.bn(t, training=training)                       # \"training\" - passed to BN or DROPOUT if present\n",
    "        t = tf.nn.relu(t)                                       # custom ACTIVATION\n",
    "        return t\n",
    "    \n",
    "class LinearUnit(layers.Layer):\n",
    "    def __init__(self, out_size, activation):\n",
    "        super().__init__()\n",
    "        self.fc = layers.Dense(out_size, activation=activation) # layers ACTIVATION\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        t = self.fc(input_tensor)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(models.Model):\n",
    "    def __init__(self, image_shape):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvUnit(32, 3)                       # activated - custom\n",
    "        self.conv2 = ConvUnit(64, 3)\n",
    "        self.fc1 = LinearUnit(1024, activation='relu')     # activated - layers\n",
    "        self.fc2 = LinearUnit(128 , activation='relu')\n",
    "        self.out = LinearUnit(10  , activation='sigmoid')\n",
    "        # GENERATE SUMMARY\n",
    "        self.image_shape = image_shape\n",
    "        self.build(input_shape=(None, *image_shape))\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        t = self.conv1(input_tensor, training=training)    # has BN\n",
    "        t = self.conv2(t, training=training)\n",
    "        t = layers.Flatten()(t)                            # FLATTEN returns callable\n",
    "        t = self.fc1(t)\n",
    "        t = self.fc2(t)\n",
    "        t = self.out(t)\n",
    "        return t\n",
    "    \n",
    "    def model(self):\n",
    "        t = keras.Input(shape=self.image_shape)\n",
    "        return keras.Model(inputs=[t], outputs=self.call(t))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel(image_shape=(28,28,1))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # from_logits = False (DEFAULT) ## EXPLORE ##\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv_unit (ConvUnit)         (None, 26, 26, 32)        448       \n",
      "_________________________________________________________________\n",
      "conv_unit_1 (ConvUnit)       (None, 24, 24, 64)        18752     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "linear_unit (LinearUnit)     (None, 1024)              37749760  \n",
      "_________________________________________________________________\n",
      "linear_unit_1 (LinearUnit)   (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "linear_unit_2 (LinearUnit)   (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 37,901,450\n",
      "Trainable params: 37,901,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
