{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fashion_dataset = keras.datasets.cifar10\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE NORMALIZING:\n",
      "IMAGES:  255\n",
      "LABELS:  9\n"
     ]
    }
   ],
   "source": [
    "print(\"BEFORE NORMALIZING:\")\n",
    "print(\"IMAGES: \",train_images.max()) # RANGE: 0-255\n",
    "print(\"LABELS: \",train_labels.max()) # RANGE: 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER NORMALIZING:\n",
      "IMAGES:  1.0\n",
      "IMAGES:  1.0\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "print(\"AFTER NORMALIZING:\")\n",
    "print(\"IMAGES: \",train_images.max()) # RANGE: 0-1\n",
    "print(\"IMAGES: \",test_images.max()) # RANGE: 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(2,2))\n",
    "# plt.imshow(train_images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# EXPLORE MORE\n",
    "'''\n",
    "tf.image.resize      -   resize\n",
    "image.img_to_array   -   IMG to NP_ARRAY\n",
    "ImageDataGenerator   -   create augmented dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # from_logits = False (DEFAULT) ## EXPLORE ##\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 188,810\n",
      "Trainable params: 188,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 64s 82ms/step - loss: 1.9898 - accuracy: 0.3444\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 70s 89ms/step - loss: 1.8740 - accuracy: 0.4584\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 64s 82ms/step - loss: 1.8327 - accuracy: 0.5057\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 76s 97ms/step - loss: 1.8032 - accuracy: 0.5424\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 65s 83ms/step - loss: 1.7771 - accuracy: 0.5711\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 59s 75ms/step - loss: 1.7590 - accuracy: 0.5941\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 53s 68ms/step - loss: 1.7409 - accuracy: 0.6130\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 60s 76ms/step - loss: 1.7265 - accuracy: 0.6294\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 1.7134 - accuracy: 0.6458\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 59s 75ms/step - loss: 1.7038 - accuracy: 0.6612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1396c2190>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 1.7346 - accuracy: 0.6353\n",
      "ACC:  0.6352999806404114\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"ACC: \",test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# PREDICT\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "print(test_images.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
