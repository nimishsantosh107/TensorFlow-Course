{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fashion_dataset = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE NORMALIZING:\n",
      "IMAGES:  255\n",
      "LABELS:  9\n"
     ]
    }
   ],
   "source": [
    "print(\"BEFORE NORMALIZING:\")\n",
    "print(\"IMAGES: \",train_images.max()) # RANGE: 0-255\n",
    "print(\"LABELS: \",train_labels.max()) # RANGE: 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER NORMALIZING:\n",
      "IMAGES:  1.0\n",
      "IMAGES:  1.0\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "print(\"AFTER NORMALIZING:\")\n",
    "print(\"IMAGES: \",train_images.max()) # RANGE: 0-1\n",
    "print(\"IMAGES: \",test_images.max()) # RANGE: 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(2,2))\n",
    "# plt.imshow(train_images[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# CONVERT (x,y) -> (x,y,c)\n",
    "train_images = train_images.reshape(*train_images.shape, 1).astype(np.float32)\n",
    "test_images = test_images.reshape(*test_images.shape, 1).astype(np.float32)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvUnit(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size):              # \"kernel_size\" - 3 or (3,3) | \"input_shape\" passed to first block\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size)\n",
    "        self.bn   = layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, input_tensor, training=False):               # \"training\" - depends on FIT or EVALUATE (BN or DROPOUT)\n",
    "        t = self.conv(input_tensor)\n",
    "        t = self.bn(t, training=training)                       # \"training\" - passed to BN or DROPOUT if present\n",
    "        t = tf.nn.relu(t)                                       # custom ACTIVATION\n",
    "        return t\n",
    "    \n",
    "class LinearUnit(layers.Layer):\n",
    "    def __init__(self, out_size, activation):\n",
    "        super().__init__()\n",
    "        self.fc = layers.Dense(out_size, activation=activation) # layers ACTIVATION\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        t = self.fc(input_tensor)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(models.Model):\n",
    "    def __init__(self, image_shape):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvUnit(16, 3)                       # activated - custom\n",
    "        self.conv2 = ConvUnit(32, 3)\n",
    "        self.fc1 = LinearUnit(128 , activation='relu')     # activated - layers\n",
    "        self.out = LinearUnit(10  , activation='softmax')\n",
    "        # GENERATE SUMMARY\n",
    "        self.image_shape = image_shape\n",
    "        self.build(input_shape=(None, *image_shape))\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        t = self.conv1(input_tensor, training=training)    # has BN\n",
    "        t = self.conv2(t, training=training)\n",
    "        t = layers.Flatten()(t)                            # FLATTEN returns callable\n",
    "        t = self.fc1(t)\n",
    "        t = self.out(t)\n",
    "        return t\n",
    "    \n",
    "    def model(self):\n",
    "        t = keras.Input(shape=self.image_shape)\n",
    "        return keras.Model(inputs=[t], outputs=self.call(t))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT MODEL\n",
    "model = CustomModel(image_shape=(28,28,1))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # from_logits = False (DEFAULT) ## EXPLORE ##\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv_unit (ConvUnit)         (None, 26, 26, 16)        224       \n",
      "_________________________________________________________________\n",
      "conv_unit_1 (ConvUnit)       (None, 24, 24, 32)        4768      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "linear_unit (LinearUnit)     (None, 128)               2359424   \n",
      "_________________________________________________________________\n",
      "linear_unit_1 (LinearUnit)   (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,365,706\n",
      "Trainable params: 2,365,610\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 112s 119ms/step - loss: 0.4226 - accuracy: 0.8572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13481b130>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN - passes \"training=True\" to CALL\n",
    "model.fit(train_images, train_labels, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3457 - accuracy: 0.8752\n",
      "ACC:  0.8751999735832214\n"
     ]
    }
   ],
   "source": [
    "# EVAL - passes \"training=False\" to CALL\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"ACC: \",test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(models.Model):\n",
    "    '''\n",
    "    PROPERTIES:\n",
    "        self.trainable_variables = trainable parameters in model [autodetected]\n",
    "        self.compiled_loss = \"callable loss\" passed to trainer.compile()\n",
    "        self.compiled_metrics = \"callable metrics\" passed to trainer.compile()\n",
    "        self.metrics = metric results stored in model\n",
    "        self.optimizer = \"callable optimizer\" passed to trainer.compile()\n",
    "        \n",
    "    OVERRIDE:\n",
    "        def compile(): - can be used to overrider trainer.compile() and store loss,optimizer,metrics\n",
    "        def train_step(): - to use in trainer.fit()\n",
    "        def test_step(): - to use in trainer.evaluate()\n",
    "    '''\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    # FIT\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        # FORWARD PROP, LOSS CALC with GRAPH TRACKING\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred)                  # \"loss\" from trainer.compile()\n",
    "            \n",
    "        # GRAD CALCULATE & BACKPROP \n",
    "        gradients = tape.gradient(loss, self.trainable_variables) # grad of \"loss\" wrt \"network_weights\"\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # RETURN METRICS TO PRINT\n",
    "        self.compiled_metrics.update_state(y, y_pred)             # \"metrics\" from trainer.compile()\n",
    "        return {metric.name: metric.result() for metric in self.metrics}\n",
    "        \n",
    "        \n",
    "    # EVALUATE\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        y_pred = model(x, training=False)\n",
    "        \n",
    "        # RETURN METRICS TO PRINT\n",
    "        self.compiled_metrics.update_state(y, y_pred)             # \"metrics\" from trainer.compile()\n",
    "        return {metric.name: metric.result() for metric in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT MODEL\n",
    "model = CustomModel(image_shape=(28,28,1))\n",
    "\n",
    "trainer = CustomTrainer(model)\n",
    "\n",
    "trainer.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy', # from_logits = False (DEFAULT) ## EXPLORE ##\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 89s 95ms/step - loss: 0.4354 - accuracy: 0.8522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1325ee5b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(train_images, train_labels, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 0.0000e+00 - accuracy: 0.8879\n",
      "ACC:  0.8878999948501587\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = trainer.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"ACC: \",test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 2\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE TRAIN AND TEST DATA\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT MODEL\n",
    "model = CustomModel(image_shape=(28,28,1))\n",
    "\n",
    "# INIT TRAIN UTILS\n",
    "optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "accuracy_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc411907cc1f4da6877f63fd99aaa4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  0 \tACCURACY 0.91 \tLOSS:  0.25\n",
      "EPOCH:  1 \tACCURACY 0.93 \tLOSS:  0.19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN RUN\n",
    "losses, accuracies = [], []\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    batch_loss_accumulator = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_dataset):\n",
    "        x, y = batch\n",
    "        \n",
    "        # FORWARD PROP, LOSS CALC with GRAPH TRACKING\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_preds = model(x, training=True)\n",
    "            loss = loss_fn(y, y_preds)\n",
    "            \n",
    "        # GRAD CALCULATE & BACKPROP\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        \n",
    "        # UPDATE LOSS ACCUMULATOR & METRICS\n",
    "        batch_loss_accumulator += loss.numpy()\n",
    "        accuracy_metric.update_state(y, y_preds)\n",
    "        \n",
    "    epoch_loss = batch_loss_accumulator / len(train_dataset)\n",
    "    epoch_accuracy = accuracy_metric.result().numpy()\n",
    "    accuracy_metric.reset_states()\n",
    "    \n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_accuracy)\n",
    "    \n",
    "    print(\"EPOCH: \",epoch,\"\\tACCURACY\",round(epoch_accuracy,2),\"\\tLOSS: \",round(epoch_loss,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4728ca879ed648788b260d540aac963b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=938.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACCURACY 0.93 \tLOSS:  0.21\n"
     ]
    }
   ],
   "source": [
    "# TEST RUN\n",
    "batch_loss_accumulator = 0\n",
    "\n",
    "for batch in tqdm(train_dataset):\n",
    "    x, y = batch\n",
    "    \n",
    "    y_preds = model(x, training=False)\n",
    "    # LOSS\n",
    "    loss = loss_fn(y, y_preds)\n",
    "    batch_loss_accumulator += loss.numpy()\n",
    "    # ACCURACY\n",
    "    accuracy_metric.update_state(y, y_preds)\n",
    "    \n",
    "test_loss = batch_loss_accumulator / len(train_dataset)\n",
    "test_accuracy = accuracy_metric.result().numpy()\n",
    "\n",
    "print(\"ACCURACY\",round(test_accuracy,2),\"\\tLOSS: \",round(test_loss,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training Loop without Eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 2\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE TRAIN AND TEST DATA\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT MODEL\n",
    "model = CustomModel(image_shape=(28,28,1))\n",
    "\n",
    "# INIT TRAIN UTILS\n",
    "optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "accuracy_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EAGER DISABLED TRAIN STEP\n",
    "@tf.function\n",
    "def train_step(x,y):\n",
    "    # FORWARD PROP, LOSS CALC with GRAPH TRACKING\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_preds = model(x, training=True)\n",
    "        loss = loss_fn(y, y_preds)\n",
    "\n",
    "    # GRAD CALCULATE & BACKPROP\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    return loss, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d18fc688900414f86de2ac3d38bc509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  0 \tACCURACY 0.86 \tLOSS:  0.43\n",
      "EPOCH:  1 \tACCURACY 0.91 \tLOSS:  0.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN RUN\n",
    "losses, accuracies = [], []\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    batch_loss_accumulator = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_dataset):\n",
    "        x, y = batch\n",
    "        \n",
    "        # EAGER DISABLED TRAIN STEP\n",
    "        loss, y_preds = train_step(x,y)\n",
    "        \n",
    "        # UPDATE LOSS ACCUMULATOR & METRICS\n",
    "        batch_loss_accumulator += loss.numpy()\n",
    "        accuracy_metric.update_state(y, y_preds)\n",
    "        \n",
    "    epoch_loss = batch_loss_accumulator / len(train_dataset)\n",
    "    epoch_accuracy = accuracy_metric.result().numpy()\n",
    "    accuracy_metric.reset_states()\n",
    "    \n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_accuracy)\n",
    "    \n",
    "    print(\"EPOCH: \",epoch,\"\\tACCURACY\",round(epoch_accuracy,2),\"\\tLOSS: \",round(epoch_loss,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EAGER DISABLED TEST STEP\n",
    "@tf.function\n",
    "def test_step(x,y):\n",
    "    y_preds = model(x, training=False)\n",
    "    loss = loss_fn(y, y_preds)\n",
    "    \n",
    "    return loss, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021745e3e9574e8e9967da3dd5a8032e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=938.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACCURACY 0.93 \tLOSS:  0.21\n"
     ]
    }
   ],
   "source": [
    "# TEST RUN\n",
    "batch_loss_accumulator = 0\n",
    "\n",
    "for batch in tqdm(train_dataset):\n",
    "    x, y = batch\n",
    "    \n",
    "    # EAGER DISABLED EST STEP\n",
    "    loss, y_preds = test_step(x,y)\n",
    "    \n",
    "    batch_loss_accumulator += loss.numpy()\n",
    "    # ACCURACY\n",
    "    accuracy_metric.update_state(y, y_preds)\n",
    "    \n",
    "test_loss = batch_loss_accumulator / len(train_dataset)\n",
    "test_accuracy = accuracy_metric.result().numpy()\n",
    "\n",
    "print(\"ACCURACY\",round(test_accuracy,2),\"\\tLOSS: \",round(test_loss,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
